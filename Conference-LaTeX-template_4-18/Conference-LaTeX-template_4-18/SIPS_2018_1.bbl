% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' in \emph{Advances in neural information
  processing systems}, 2012, pp. 1097--1105.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2016, pp. 770--778.

\bibitem{szegedy2015going}
\BIBentryALTinterwordspacing
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~E. Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich, ``Going deeper with convolutions,''
  \emph{CoRR}, vol. abs/1409.4842, 2014. [Online]. Available:
  \url{http://arxiv.org/abs/1409.4842}
\BIBentrySTDinterwordspacing

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{cs231}
\BIBentryALTinterwordspacing
A.~Karpathy. Cs231n: Convolutional neural networks for visual recognition.
  [Online]. Available: \url{http://cs231n.github.io/}
\BIBentrySTDinterwordspacing

\bibitem{glorot2011deep}
X.~Glorot, A.~Bordes, and Y.~Bengio, ``Deep sparse rectifier neural networks,''
  in \emph{Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics}, 2011, pp. 315--323.

\bibitem{Goodfellow-et-al-2016}
I.~Goodfellow, Y.~Bengio, and A.~Courville, \emph{Deep Learning}.\hskip 1em
  plus 0.5em minus 0.4em\relax MIT Press, 2016,
  \url{http://www.deeplearningbook.org}.

\bibitem{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov,
  ``Dropout: A simple way to prevent neural networks from overfitting,''
  \emph{The Journal of Machine Learning Research}, vol.~15, no.~1, pp.
  1929--1958, 2014.

\bibitem{zhu2017prune}
M.~Zhu and S.~Gupta, ``To prune, or not to prune: exploring the efficacy of
  pruning for model compression,'' \emph{arXiv preprint arXiv:1710.01878},
  2017.

\bibitem{han2016eie}
S.~Han, X.~Liu, H.~Mao, J.~Pu, A.~Pedram, M.~A. Horowitz, and W.~J. Dally,
  ``Eie: efficient inference engine on compressed deep neural network,'' in
  \emph{Computer Architecture (ISCA), 2016 ACM/IEEE 43rd Annual International
  Symposium on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2016, pp.
  243--254.

\bibitem{jouppi2017datacenter}
N.~P. Jouppi, C.~Young, N.~Patil, D.~Patterson, G.~Agrawal, R.~Bajwa, S.~Bates,
  S.~Bhatia, N.~Boden, A.~Borchers \emph{et~al.}, ``In-datacenter performance
  analysis of a tensor processing unit,'' in \emph{Proceedings of the 44th
  Annual International Symposium on Computer Architecture}.\hskip 1em plus
  0.5em minus 0.4em\relax ACM, 2017, pp. 1--12.

\bibitem{DBLP:journals/corr/IandolaMAHDK16}
\BIBentryALTinterwordspacing
F.~N. Iandola, M.~W. Moskewicz, K.~Ashraf, S.~Han, W.~J. Dally, and K.~Keutzer,
  ``Squeezenet: Alexnet-level accuracy with 50x fewer parameters and
  {\textless}1mb model size,'' \emph{CoRR}, vol. abs/1602.07360, 2016.
  [Online]. Available: \url{http://arxiv.org/abs/1602.07360}
\BIBentrySTDinterwordspacing

\bibitem{jiang2017xnor}
L.~Jiang, M.~Kim, W.~Wen, and D.~Wang, ``Xnor-pop: A processing-in-memory
  architecture for binary convolutional neural networks in wide-io2 drams,'' in
  \emph{Low Power Electronics and Design (ISLPED, 2017 IEEE/ACM International
  Symposium on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 1--6.

\bibitem{tang2017binary}
T.~Tang, L.~Xia, B.~Li, Y.~Wang, and H.~Yang, ``Binary convolutional neural
  network on rram,'' in \emph{Design Automation Conference (ASP-DAC), 2017 22nd
  Asia and South Pacific}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017,
  pp. 782--787.

\bibitem{han2015deep}
S.~Han, H.~Mao, and W.~J. Dally, ``Deep compression: Compressing deep neural
  networks with pruning, trained quantization and huffman coding,'' \emph{arXiv
  preprint arXiv:1510.00149}, 2015.

\bibitem{Eyeriss}
Y.~H. Chen, J.~Emer, and V.~Sze, ``Eyeriss: A spatial architecture for
  energy-efficient dataflow for convolutional neural networks,'' \emph{IEEE
  Micro}, pp. 1--1, 2017.

\bibitem{zhang2015optimizing}
C.~Zhang, P.~Li, G.~Sun, Y.~Guan, B.~Xiao, and J.~Cong, ``Optimizing fpga-based
  accelerator design for deep convolutional neural networks,'' in
  \emph{Proceedings of the 2015 ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays}.\hskip 1em plus 0.5em minus 0.4em\relax ACM,
  2015, pp. 161--170.

\bibitem{shen2017escher}
Y.~Shen, M.~Ferdman, and P.~Milder, ``Escher: A cnn accelerator with flexible
  buffering to minimize off-chip transfer,'' in \emph{Field-Programmable Custom
  Computing Machines (FCCM), 2017 IEEE 25th Annual International Symposium
  on}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 93--100.

\bibitem{shen2017maximizing}
------, ``Maximizing cnn accelerator efficiency through resource
  partitioning,'' in \emph{Proceedings of the 44th Annual International
  Symposium on Computer Architecture}.\hskip 1em plus 0.5em minus 0.4em\relax
  ACM, 2017, pp. 535--547.

\bibitem{ILSVRC15}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, A.~C. Berg, and L.~Fei-Fei, ``{ImageNet
  Large Scale Visual Recognition Challenge},'' \emph{International Journal of
  Computer Vision (IJCV)}, vol. 115, no.~3, pp. 211--252, 2015.

\bibitem{motamedi2016design}
M.~Motamedi, P.~Gysel, V.~Akella, and S.~Ghiasi, ``Design space exploration of
  fpga-based deep convolutional neural networks,'' in \emph{Design Automation
  Conference (ASP-DAC), 2016 21st Asia and South Pacific}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2016, pp. 575--580.

\bibitem{lepsucd}
\BIBentryALTinterwordspacing
http://lepsucd.com/. Alexnet forward path. [Online]. Available:
  \url{https://github.com/pmgysel/alexnet-forwardpath}
\BIBentrySTDinterwordspacing

\end{thebibliography}
