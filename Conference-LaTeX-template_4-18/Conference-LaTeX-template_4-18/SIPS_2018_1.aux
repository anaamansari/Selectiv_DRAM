\relax 
\citation{krizhevsky2012imagenet,he2016deep,szegedy2015going,simonyan2014very}
\citation{cs231}
\citation{glorot2011deep}
\citation{krizhevsky2012imagenet}
\citation{Goodfellow-et-al-2016}
\citation{srivastava2014dropout,zhu2017prune}
\citation{han2016eie,jouppi2017datacenter,DBLP:journals/corr/IandolaMAHDK16,jiang2017xnor,tang2017binary}
\citation{han2015deep}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The functions involved in computing a CNN layer}}{1}}
\newlabel{cnn_ref}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II} Motivation}{1}}
\citation{Eyeriss,zhang2015optimizing,shen2017escher,shen2017maximizing}
\citation{han2015deep,DBLP:journals/corr/IandolaMAHDK16}
\citation{ILSVRC15}
\citation{krizhevsky2012imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces convolutional operation}}{2}}
\newlabel{cnn_layer}{{2}{2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces 2D convolutional operation}}{2}}
\newlabel{alg1}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Non-linear activation functions}}{2}}
\newlabel{act}{{3}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Networks}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}AlexNet}{2}}
\citation{simonyan2014very}
\citation{motamedi2016design,lepsucd}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Effect of quantization optimization techniques \cite  {han2015deep, DBLP:journals/corr/IandolaMAHDK16}}}{3}}
\newlabel{quant_eff}{{I}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Filter kernels for each layer}}{3}}
\newlabel{alex_w}{{II}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}VGGNET16}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Fixed Point Arithmetic Analysis}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Forward Path of AlexNet with fixed precision sM,N}}{3}}
\newlabel{fp}{{4}{3}}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,references_1}
\bibcite{krizhevsky2012imagenet}{1}
\bibcite{he2016deep}{2}
\bibcite{szegedy2015going}{3}
\bibcite{simonyan2014very}{4}
\bibcite{cs231}{5}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces AlexNET:Results for fixed point precision quantization on output fmaps input and weights (s32,22), output double precision}}{4}}
\newlabel{res1}{{III}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces AlexNET:Results for fixed point precision quantization on output fmaps input and weights (s16,7), output double precision}}{4}}
\newlabel{res2}{{IV}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces VGGNET16:Results for fixed point precision quantization on output fmaps input and weights (s45,7), output double precision}}{4}}
\newlabel{res3}{{V}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {VI}{\ignorespaces VGGNET16:Results for fixed point precision quantization on output fmaps input and weights (s24,10), output double precision}}{4}}
\newlabel{res4}{{VI}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{4}}
\@writefile{toc}{\contentsline {section}{References}{4}}
\bibcite{glorot2011deep}{6}
\bibcite{Goodfellow-et-al-2016}{7}
\bibcite{srivastava2014dropout}{8}
\bibcite{zhu2017prune}{9}
\bibcite{han2016eie}{10}
\bibcite{jouppi2017datacenter}{11}
\bibcite{DBLP:journals/corr/IandolaMAHDK16}{12}
\bibcite{jiang2017xnor}{13}
\bibcite{tang2017binary}{14}
\bibcite{han2015deep}{15}
\bibcite{Eyeriss}{16}
\bibcite{zhang2015optimizing}{17}
\bibcite{shen2017escher}{18}
\bibcite{shen2017maximizing}{19}
\bibcite{ILSVRC15}{20}
\bibcite{motamedi2016design}{21}
\bibcite{lepsucd}{22}
